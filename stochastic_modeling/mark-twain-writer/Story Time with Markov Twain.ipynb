{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Time with Markov Twain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text and Getting Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JLD;\n",
    "using ForwardDiff;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add two workers to do processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# addprocs(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, Julia interpreter prints last variable of cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function clean_corpus(text, regex; normalize = true, lower_case = true)\n",
    "    if normalize\n",
    "        # replace control characters with spaces\n",
    "        text = normalize_string(text, stripmark = true, stripignore = true, stripcc = true)\n",
    "    end\n",
    "    \n",
    "    if lower_case\n",
    "        text = lowercase(text)\n",
    "    end\n",
    "    \n",
    "    # remove unwanted characters\n",
    "    text = replace(text, regex, \"\")\n",
    "    \n",
    "    # remove \"\"\n",
    "    text = split(text, \" \")\n",
    "    target_index = 1\n",
    "    for i in 1:length(text)\n",
    "        target_index = findnext(text, \"\", target_index)\n",
    "        if target_index == 0\n",
    "            break\n",
    "        else\n",
    "            splice!(text, target_index)\n",
    "        end\n",
    "    end        \n",
    "    text = join(text, \" \")\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"mark_twain_books/adventures_of_tom_sawyer.txt\")\n",
    "ats = readall(f);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create regex object (I prefer whitelisting characters I want to keep)\n",
    "chars_to_remove = r\"[^a-z ]\"\n",
    "ats_clean = clean_corpus(ats, chars_to_remove);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define text to numeric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function text_to_numeric(text, symbols)\n",
    "    numeric_text = []\n",
    "    for each in text\n",
    "        push!(numeric_text, findfirst(symbols, each))\n",
    "    end\n",
    "    # convert to tuple?\n",
    "    numeric_text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function numeric_to_text(numeric, symbols)\n",
    "    text= []\n",
    "    for num in numeric\n",
    "        push!(text, symbols[num])\n",
    "    end\n",
    "    text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if ngram = 2, M will actually need to be a 3-dimensional array\n",
    "function get_corpus_frequencies(corpus, ngram; groupby = \"words\")\n",
    "    if groupby == \"chars\"\n",
    "        corpus = split(corpus, \"\")\n",
    "    else        \n",
    "        corpus = split(corpus, \" \")\n",
    "    end\n",
    "    \n",
    "    # find unique symbols\n",
    "    unique_symbols = unique(corpus)   \n",
    "    # convert text to numbers\n",
    "    corpus_numeric = text_to_numeric(corpus, unique_symbols);\n",
    "    # create M\n",
    "    dimensions = repeat([length(unique_symbols)], outer=[ngram])\n",
    "    M = repeat([0], outer = dimensions)\n",
    "    # get frequencies for ngram of text\n",
    "    for i in 1:length(corpus)-ngram+1\n",
    "        M[corpus_numeric[i:i+ngram-1]...] += 1\n",
    "    end\n",
    "    \n",
    "    M\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure this frequency array works on a subset of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_ats_clean = length(split(ats_clean, \" \"))\n",
    "# text subset\n",
    "ats_subset = join(split(ats_clean, \" \")[1:round(Int64, len_ats_clean/2)], \" \")\n",
    "@time M = get_corpus_frequencies(ats_subset, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine all three Mark Twain novels and create a frequency array for the whole text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import other books\n",
    "f = open(\"mark_twain_books/huckleberry_finn.txt\")\n",
    "hf = readall(f)\n",
    "f = open(\"mark_twain_books/the_prince_and_the_pauper.txt\")\n",
    "tpatp = readall(f)\n",
    "\n",
    "# clean other books\n",
    "hf_clean = clean_corpus(hf, chars_to_remove)\n",
    "tpatp_clean = clean_corpus(tpatp, chars_to_remove)\n",
    "\n",
    "# combine all books\n",
    "big_corpus_clean = ats_clean * \" \" * hf_clean * \" \" * tpatp_clean;\n",
    "# M_2 = get_corpus_frequencies(big_corpus_clean, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this on desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @time M_3 = get_corpus_frequencies(big_corpus_clean, 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save M_2 object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(\"M_2.jld\", \"M_2\", M_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import M_2 object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M_2 = load(\"M_2.jld\", \"M_2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function choose_next_state(distribution, r)\n",
    "    # only consider entries that are non-zero\n",
    "    nonzero_entries = findn(distribution)\n",
    "    distribution_nonzero = distribution[nonzero_entries]\n",
    "    ranges = cumsum(distribution_nonzero)\n",
    "    \n",
    "    for (idx, range) in enumerate(ranges)\n",
    "        if r < range\n",
    "            return nonzero_entries[idx]\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function markov_model(ϕ, num_steps, unique_symbols, ngram, M_2)\n",
    "\n",
    "    # create empty array to store result of Markov jumping from state to state\n",
    "    markov_chain_text = []\n",
    "    push!(markov_chain_text, ϕ)\n",
    "    \n",
    "    current_state = text_to_numeric(split(ϕ, \" \"), unique_symbols)\n",
    "    \n",
    "    for step in 1:num_steps\n",
    "        # normalize row\n",
    "        distribution = M_2[current_state, :][:] / sum(M_2[current_state, :][:])\n",
    "\n",
    "        # randomly choose next word\n",
    "        # generate random number betweeen 0 and 1\n",
    "        r = rand()\n",
    "        next_word_idx = choose_next_state(distribution, r)\n",
    "        next_word = numeric_to_text([next_word_idx], unique_symbols)[1]\n",
    "        push!(markov_chain_text, next_word)\n",
    "        current_state = text_to_numeric(markov_chain_text[end-ngram+1:end], unique_symbols)\n",
    "    end\n",
    "    \n",
    "    markov_chain_text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_phi(cleaned_corpus, ngram; groupby = \"words\")\n",
    "    if groupby == \"chars\"\n",
    "        cleaned_corpus_array = split(cleaned_corpus, \"\")\n",
    "    else\n",
    "        cleaned_corpus_array = split(cleaned_corpus, \" \")\n",
    "        \n",
    "    end\n",
    "    starting_point = rand(1:length(cleaned_corpus_array)-ngram)\n",
    "    ϕ = join(cleaned_corpus_array[starting_point:starting_point+ngram-1], \" \") \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "unique_symbols = unique(split(big_corpus_clean, \" \"))\n",
    "ngram = 1\n",
    "# choose random ngram set of symbols from text\n",
    "ϕ = get_phi(big_corpus_clean, ngram, groupby = \"words\")\n",
    "\n",
    "markov_chain_text = markov_model(ϕ, num_steps, unique_symbols, ngram, M_2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.6",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
