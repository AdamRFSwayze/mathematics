{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Time with Markov Twain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add two workers to do processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# addprocs(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, Julia interpreter prints last variable of cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function clean_corpus(text, regex, normalize = true, lower_case = true)\n",
    "    if normalize\n",
    "        # replace control characters with spaces\n",
    "        text = normalize_string(text, stripmark = true, stripignore = true, stripcc = true)\n",
    "    end\n",
    "    \n",
    "    if lower_case\n",
    "        text = lowercase(text)\n",
    "    end\n",
    "    \n",
    "    # remove unwanted characters\n",
    "    text = replace(text, regex, \"\")\n",
    "    \n",
    "    # remove \"\"\n",
    "    text = split(text, \" \")\n",
    "    target_index = 1\n",
    "    for i in 1:length(text)\n",
    "        target_index = findnext(text, \"\", target_index)\n",
    "        if target_index == 0\n",
    "            break\n",
    "        else\n",
    "            splice!(text, target_index)\n",
    "        end\n",
    "    end        \n",
    "    text = join(text, \" \")\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"mark_twain/adventures_of_tom_sawyer.txt\")\n",
    "ats = readall(f);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create regex object (I prefer whitelisting characters I want to keep)\n",
    "chars_to_remove = r\"[^a-z ]\"\n",
    "ats_clean = clean_corpus(ats, chars_to_remove);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define text to numeric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function text_to_numeric(symbols, text)\n",
    "    numeric_text = []\n",
    "    for each in text\n",
    "        push!(numeric_text, findfirst(symbols, each))\n",
    "    end\n",
    "    # convert to tuple?\n",
    "    numeric_text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function numeric_to_text(symbols, numeric)\n",
    "    text= []\n",
    "    for num in numeric\n",
    "        push!(text, symbols[num])\n",
    "    end\n",
    "    text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_corpus_frequencies(corpus, ngram, groupby = \"words\")\n",
    "    if groupby == \"chars\"\n",
    "        corpus = split(corpus, \"\")\n",
    "    else        \n",
    "        corpus = split(corpus, \" \")\n",
    "    end\n",
    "    \n",
    "    # find unique symbols\n",
    "    unique_symbols = unique(corpus)   \n",
    "    # convert text to numbers\n",
    "    corpus_numeric = text_to_numeric(unique_symbols, corpus);\n",
    "    # create M\n",
    "    dimensions = repeat([length(unique_symbols)], outer=[ngram])\n",
    "    M = repeat([0], outer = dimensions)\n",
    "    # get frequencies for ngram of text\n",
    "    for i in 1:length(corpus)-ngram+1\n",
    "        M[corpus_numeric[i:i+ngram-1]...] += 1\n",
    "    end\n",
    "    \n",
    "    M\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure this frequency array works on a subset of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15.876667 seconds (239.61 M allocations: 7.367 GB, 3.72% gc time)\n"
     ]
    }
   ],
   "source": [
    "len_ats_clean = length(split(ats_clean, \" \"))\n",
    "# text subset\n",
    "ats_subset = join(split(ats_clean, \" \")[1:round(Int64, len_ats_clean/2)], \" \")\n",
    "@time M = get_corpus_frequencies(ats_subset, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take it a step up and get a frequency array for the whole text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36.419307 seconds (529.34 M allocations: 16.274 GB, 3.95% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time M = get_corpus_frequencies(ats_clean, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baby purs :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.6",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
