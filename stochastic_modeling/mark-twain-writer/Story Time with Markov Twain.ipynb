{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Time with Markov Twain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text and Getting Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JLD;\n",
    "using ForwardDiff;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add two workers to do processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# addprocs(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, Julia interpreter prints last variable of cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function clean_corpus(text, regex; normalize = true, lower_case = true)\n",
    "    if normalize\n",
    "        # replace control characters with spaces\n",
    "        text = normalize_string(text, stripmark = true, stripignore = true, stripcc = true)\n",
    "    end\n",
    "    \n",
    "    if lower_case\n",
    "        text = lowercase(text)\n",
    "    end\n",
    "    \n",
    "    # remove unwanted characters\n",
    "    text = replace(text, regex, \"\")\n",
    "    \n",
    "    # remove \"\"\n",
    "    text = split(text)\n",
    "    target_index = 1\n",
    "    for i in 1:length(text)\n",
    "        target_index = findnext(text, \"\", target_index)\n",
    "        if target_index == 0\n",
    "            break\n",
    "        else\n",
    "            splice!(text, target_index)\n",
    "        end\n",
    "    end        \n",
    "    text = join(text, \" \")\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"mark_twain_books/adventures_of_tom_sawyer.txt\")\n",
    "ats = readall(f);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create regex object (I prefer whitelisting characters I want to keep)\n",
    "chars_to_remove = r\"[^a-z ]\"\n",
    "ats_clean = clean_corpus(ats, chars_to_remove);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define text to numeric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function text_to_numeric(text, symbols)\n",
    "    numeric_text = []\n",
    "    for each in text\n",
    "        push!(numeric_text, findfirst(symbols, each))\n",
    "    end\n",
    "\n",
    "    numeric_text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function numeric_to_text(numeric, symbols)\n",
    "    text= []\n",
    "    for num in numeric\n",
    "        push!(text, symbols[num])\n",
    "    end\n",
    "    \n",
    "    text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_corpus_frequencies(corpus, ngram; groupby = \"words\")\n",
    "    # to get frequency of symbol x after ngram symbols\n",
    "    ngram = ngram + 1\n",
    "    if groupby == \"chars\"\n",
    "        corpus = split(corpus, \"\")\n",
    "    else        \n",
    "        corpus = split(corpus)\n",
    "    end\n",
    "    \n",
    "    # find unique symbols\n",
    "    unique_symbols = unique(corpus)   \n",
    "    # convert text to numbers\n",
    "    corpus_numeric = text_to_numeric(corpus, unique_symbols);\n",
    "    # create M\n",
    "    dimensions = repeat([length(unique_symbols)], outer=[ngram])\n",
    "    M = repeat(zeros(UInt16, 1), outer = dimensions)\n",
    "    # get frequencies for ngram of text\n",
    "    for i in 1:length(corpus)-ngram+1\n",
    "        M[corpus_numeric[i:i+ngram-1]...] += 1\n",
    "    end\n",
    "    \n",
    "    M\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure this frequency array works on a subset of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_ats_clean = length(split(ats_clean))\n",
    "# text subset\n",
    "ats_subset = join(split(ats_clean)[1:round(Int64, len_ats_clean/2)], \" \")\n",
    "@time M = get_corpus_frequencies(ats_subset, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine all three Mark Twain novels and create a frequency array for the whole text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import other books\n",
    "f = open(\"mark_twain_books/huckleberry_finn.txt\")\n",
    "hf = readall(f)\n",
    "f = open(\"mark_twain_books/the_prince_and_the_pauper.txt\")\n",
    "tpatp = readall(f)\n",
    "\n",
    "# clean other books\n",
    "hf_clean = clean_corpus(hf, chars_to_remove)\n",
    "tpatp_clean = clean_corpus(tpatp, chars_to_remove)\n",
    "\n",
    "# combine all books\n",
    "big_corpus_clean = ats_clean * \" \" * hf_clean * \" \" * tpatp_clean\n",
    "# M_1 = get_corpus_frequencies(big_corpus_clean, 1);\n",
    "# save(\"M_1.jld\", \"M_1\", M_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For arrays with 64-bit entries and ngram = 2:**   \n",
    "Since I only have ~29 GB of available memory, I need to figure out how many unique symbols I can afford.  \n",
    "By solving the following inequality, I figure I need to keep the number of unique_symbols < 1550.  \n",
    "$x^3*64/8/1024^3 < 29$  \n",
    "At 1550 unqiue symbols for ngram = 2, ~23 GB of memory should be used, so that's what we'll try here.\n",
    "\n",
    "**For arrays with unsigned 16-bit entries:**  \n",
    "The inequality, $x^3*16/8/1024^3 < 29$, would allow me to have approximately ~2500 unique symbols. But for demo purposes, I'm just going to use 1452 unique symbols to conserve memory.\n",
    "\n",
    "For ngram = 3 and with the constraint of memory, we'd be looking at only low hundreds of unique words instead of thousands. As a result, we're only going to consider cases of ngram = 1 and ngram = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or take combo of half of each book if ngram = 2 due to memory restrictions\n",
    "len_ats_clean = length(split(ats_clean))\n",
    "ats_subset = join(split(ats_clean)[1:round(Int64, len_ats_clean/45)], \" \")\n",
    "len_hf_clean = length(split(hf_clean))\n",
    "hf_subset = join(split(hf_clean)[1:round(Int64, len_hf_clean/45)], \" \")\n",
    "len_tpatp_clean = length(split(tpatp_clean))\n",
    "tpatp_subset = join(split(tpatp_clean)[1:round(Int64, len_tpatp_clean/45)], \" \")\n",
    "sub_corpus_clean = ats_subset * \" \" * hf_subset * \" \" * tpatp_subset;\n",
    "\n",
    "# M1forM2 = get_corpus_frequencies(sub_corpus_clean, 1);\n",
    "# save(\"M1forM2.jld\", \"M1forM2\", M1forM2);\n",
    "# M_2 = get_corpus_frequencies(sub_corpus_clean, 2)\n",
    "# save(\"M_2.jld\", \"M_2\", M_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import frequency objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M_1 = load(\"M_1.jld\", \"M_1\")\n",
    "M_2 = load(\"M_2.jld\", \"M_2\")\n",
    "alt_M = load(\"M1forM2.jld\", \"M1forM2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function choose_next_state(distribution, r)\n",
    "    # only consider entries that are non-zero\n",
    "    nonzero_entries = findn(distribution)\n",
    "\n",
    "    distribution_nonzero = distribution[nonzero_entries]\n",
    "    ranges = cumsum(distribution_nonzero)\n",
    "    \n",
    "    for (idx, range) in enumerate(ranges)\n",
    "        if r < range\n",
    "            return nonzero_entries[idx]\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function markov_model(ϕ, num_steps, unique_symbols, ngram, M, groupby; alt_M = Void)\n",
    "\n",
    "    if groupby == \"chars\"\n",
    "        ϕ = split(ϕ, \"\")\n",
    "    else\n",
    "        ϕ = split(ϕ)\n",
    "    end\n",
    "    \n",
    "    # create empty array to store result of Markov jumping from state to state\n",
    "    markov_chain_text = []\n",
    "    append!(markov_chain_text, ϕ)\n",
    "    \n",
    "    current_state = text_to_numeric(ϕ, unique_symbols)\n",
    "    \n",
    "    for step in 1:num_steps\n",
    "        if sum(M[current_state..., :][:]) == 0 # avoid division by 0 error\n",
    "            # revert to ngram = 1 frequency array\n",
    "            if alt_M != Void && sum(alt_M[current_state[end]..., :][:]) != 0\n",
    "                # normalize row (this division automatically converts from UInt16 to Float64)\n",
    "                distribution = alt_M[current_state[end]..., :][:] / sum(alt_M[current_state[end]..., :][:])\n",
    "                r = rand()\n",
    "                next_word_idx = choose_next_state(distribution, r)\n",
    "            else\n",
    "                next_word_idx = rand(1:length(M[current_state..., :][:]))\n",
    "            end\n",
    "        else   \n",
    "            distribution = M[current_state..., :][:] / sum(M[current_state..., :][:])\n",
    "            r = rand()\n",
    "            next_word_idx = choose_next_state(distribution, r)\n",
    "        end\n",
    "\n",
    "        next_word = numeric_to_text([next_word_idx], unique_symbols)[1]\n",
    "        push!(markov_chain_text, next_word)\n",
    "        current_state = text_to_numeric(markov_chain_text[end-ngram+1:end], unique_symbols)\n",
    "    end\n",
    "    \n",
    "    markov_chain_text\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_phi(cleaned_corpus, ngram; groupby = \"words\")\n",
    "    if groupby == \"chars\"\n",
    "        cleaned_corpus_array = split(cleaned_corpus, \"\")\n",
    "    else\n",
    "        cleaned_corpus_array = split(cleaned_corpus)        \n",
    "    end\n",
    "    starting_point = rand(1:length(cleaned_corpus_array)-ngram)\n",
    "    ϕ = join(cleaned_corpus_array[starting_point:starting_point+ngram-1], \" \") \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function run(corpus, M; num_steps = 10, ngram = 2, alt_M = Void, groupby = \"words\")\n",
    "    println(\"--------------------------------------------------------\")\n",
    "    @show ngram\n",
    "    unique_symbols = unique(split(corpus))\n",
    "    # choose random ngram set of symbols from text\n",
    "    ϕ = get_phi(corpus, ngram, groupby = groupby)\n",
    "    @show ϕ\n",
    "\n",
    "    markov_chain_text = markov_model(ϕ, num_steps, unique_symbols, ngram, M, groupby, alt_M = alt_M)\n",
    "    join(markov_chain_text, \" \")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "ngram = 1\n",
      "ϕ = \"knees\"\n",
      "knees as a light he whispers that after that for as long robes of the midst of surprise of the door creaked till they called himself away down to them saying to this to get drunk i swear that you can do tom counted the tanyard so vast ceremony then anotherand then this misable business their might as dead spider i was dozing lulled by one little in the great seal about two or doubted as breakfast he knowed me what you up four avenues at last years and the girl but youve let me stared at last and almost immediately\n",
      "--------------------------------------------------------\n",
      "ngram = 2\n",
      "ϕ = \"ill learn\"\n",
      "ill learn him he was not far from london bridge the houses a very good time he got back home barely in season to help jim the small colored boy saw nextdays wood and split the kindlings before supperat least he was not far from london bridge the houses a very good time he got so downhearted and scared i did sew it with black i wish to geeminy shed stick to one or two were experiences of my own dead sisters boy poor thing and i cant hit him my old rags and my sugarhogshead again and i reckon youre a kind of swaps around and the grandmother were a couple of fiends they got drunk whenever they could then they fought each other and cried everybody took a holiday and high and low rich and poor feasted and danced and sang and got out my pipe for a smoke for the rest as he lay in the house was a valued novelty in whistling which he had just come to time when you aint too warm now though and it seemed a sight to see with gay banners waving from every balcony and housetop and splendid pageants marching along by\n"
     ]
    }
   ],
   "source": [
    "ngram1results = run(big_corpus_clean, M_1, num_steps = 100, ngram = 1);\n",
    "println(ngram1results)\n",
    "ngram2results = run(sub_corpus_clean, M_2, num_steps = 200, ngram = 2, alt_M = alt_M);\n",
    "println(ngram2results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.4.6",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
